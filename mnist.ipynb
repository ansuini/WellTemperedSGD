{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description \n",
    "\n",
    "We consider a variation on SGD that makes use of the second moment of the \n",
    "gradients as follows.\n",
    "\n",
    "The training loop has three levels :\n",
    "\n",
    "- over mini-batches\n",
    "  - we accumulate the gradients computed here and their squares without updating the parameters\n",
    "- over large batches\n",
    "  - after each large batch we do the parameters update with the modified SGD\n",
    "- over epochs\n",
    "\n",
    "Within mini-batches it is difficult to get the second moment of the gradients,\n",
    "this would require massive intervention on the nevralgic part of the automatic\n",
    "differentiation (AD) libraries. \n",
    "\n",
    "The large batches are composed of a reasonably large number of minibatches. Let us denote\n",
    "with $\\text{n}$ the number of minibatches that fit in a large batch (say n $\\approx 100$).\n",
    "\n",
    "For each mini-batch ($\\text{mb}\\approx 10$ images) in a large batch ($\\text{lb} \\approx 1000$ images) we will compute the gradient with respect to all the trainable parameters :\n",
    "\n",
    "$$\n",
    "\\nabla^{1}, \\dots, \\nabla^{\\text{n}}\n",
    "$$\n",
    "\n",
    "We accumulates these gradients and their squares (elementwise) within a large batch : \n",
    "\n",
    "$$\n",
    "\\bar{A} = \\frac{1}{n}  \\sum_{i=1}^{n} \\nabla^{i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\bar{A^{2}} = \\frac{1}{n}  \\sum_{i=1}^{n}  \\left( \\nabla^{i} \\right)^2\n",
    "$$\n",
    "\n",
    "\n",
    "We then compute the variance of the gradient as $\\sigma^2 = \\bar{A^{2}} - \\left( \\bar{A} \\right)^2$ and define the\n",
    "\n",
    "error as \n",
    "\n",
    "$$\n",
    "\\varepsilon = \\sqrt{ \\frac{\\sigma^2}{n} } = \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "The signal to noise ratio of the gradient is then\n",
    "\n",
    "$$\n",
    "\\eta = \\frac{\\bar{A}}{\\varepsilon}\n",
    "$$\n",
    "\n",
    "From the information in $\\eta$ we modify SGD as follows.\n",
    "\n",
    "At the end of the computation on a large batch we update the parameters with the \n",
    "rule \n",
    "\n",
    "$$\n",
    "w  =  w - \\lambda \\; f \\left(  \\eta \\right ) \\bar{A}\n",
    "$$\n",
    "where $\\lambda$ is the learning rate, $\\bar{A}$ is the average gradient computed on \n",
    "$\\text{n}$ mini-batches within the large batch, and $f$ is :\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{f} =  \n",
    "\\begin{cases} \n",
    "1 \\;\\;\\;\\;\\; \\text{if} \\;  \\eta \\geq 1\n",
    "\\\\\n",
    "\\eta \\;\\;\\;\\;\\; \\text{if} \\; \\eta < 1\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "so that when the gradient signal is reliable it is left unchanged while in the opposite case the gradient signal is suppressed by the prefactor $\\eta \\in [0,1)$.\n",
    "\n",
    "It is important than to monitor during the training what is the fraction of parameters\n",
    "for which the modification to the SGD applies, i.e. the fraction of weights such that $\\eta < 1$.\n",
    "\n",
    "We do that for each layer because we noticed that the signal to noise ratio can vary accross layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODIFIED_SGD = False\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'mnist'\n",
    "if DATASET     == 'mnist':\n",
    "    mb_size    = 10         # mini-batch size (default : 10)\n",
    "    n          = 100        # number of mini-batches in a large batch\n",
    "    lb_size    = n*mb_size  # large batch size (after this gradient update with modified SGD rule)  \n",
    "    n_lb       = int(60000.0/(lb_size)) # number of large batches in a epoch\n",
    "    epochs     = 100\n",
    "    lr         = 0.01\n",
    "    momentum   = 0.0    \n",
    "    mean_imgs  = 0.1307\n",
    "    std_imgs   = 0.3081\n",
    "    imgs_shape = (1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory /home/ansuini/repos/WellTemperedSGD/results/mnist/original/10_100\n",
      "Creating directory /home/ansuini/repos/WellTemperedSGD/figures/mnist/original/10_100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "ROOT = '/home/ansuini/repos/WellTemperedSGD/'\n",
    "os.chdir(ROOT)\n",
    "\n",
    "if MODIFIED_SGD:\n",
    "    RES = os.path.join(ROOT,'results', DATASET, 'modified', str(mb_size) + '_' + str(n)  )\n",
    "    if not os.path.exists(RES):\n",
    "        print('Creating directory ' + RES)\n",
    "        os.mkdir(RES)\n",
    "        \n",
    "    FIG = os.path.join(ROOT,'figures', DATASET, 'modified', str(mb_size) + '_' + str(n)  )\n",
    "    if not os.path.exists(FIG):\n",
    "        print('Creating directory ' + FIG)\n",
    "        os.mkdir(FIG)\n",
    "else:\n",
    "    RES = os.path.join(ROOT,'results', DATASET,'original', str(mb_size) + '_' + str(n)  )  \n",
    "    if not os.path.exists(RES):\n",
    "        print('Creating directory ' + RES)\n",
    "        os.mkdir(RES)\n",
    "        \n",
    "    FIG = os.path.join(ROOT,'figures', DATASET,'original', str(mb_size) + '_' + str(n)  )\n",
    "    if not os.path.exists(FIG):\n",
    "        print('Creating directory ' + FIG)\n",
    "        os.mkdir(FIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from mnist_archs import LeNet\n",
    "from wtsgd import *\n",
    "\n",
    "import pickle\n",
    "from time import time\n",
    "import numpy as np\n",
    "np.seed = 1101\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} if device.type == 'cuda' else {}\n",
    "print('Device : {}'.format( device ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(ROOT +  '/data/' + DATASET, train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((mean_imgs,), (std_imgs,))                                           \n",
    "                   ])),\n",
    "    batch_size=mb_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    \n",
    "    datasets.MNIST(ROOT + '/data/' + DATASET, train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((mean_imgs,), (std_imgs,))                       \n",
    "                   ])),\n",
    "    batch_size=mb_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()    \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABrCAYAAABAOvhBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAC+hJREFUeJzt3VFoHEUYwPEvwcrJgVei0ViUgKW0SmlKDGmDp1hbooEW2pdAKJXIQR6srYKUUovYx9hSDJpSsKa+BKr2oYKBaNNGCqakjRTyYFsJRFCESKHaSrR9KONDvfPusns7u7c7M5f8fzCQ7N3OfDs7993e7N5enVJKCQDAunrbAQAA7iMhA4AjSMgA4AgSMgA4goQMAI4gIQOAI0jIAOAIEjIAOIKEDACOICEDgCNIyADgiAfCrlBXV5dEHACwaOneMogjZABwBAkZABxBQgYAR5CQFzGlVKFks1nb4QAIQEJeZIqTcLHdu3dbigiALhKylCaxSqWxsdF2qJ6y2axks1ntM7kA3ERCBgBXqJBEJLFy4cIFK+2HlUqlVCqVSrQvdEtra6tnjFNTU8b2G4VCqVx01f33YtUW9xdD6uvr5d69e6HX27Jli5w/fz6WGEJ2QYELX5Ipj/33338XEZGmpiYb4QTy6+v+/n45cOCA4WiwFAwPD8vq1atFRKStrU1++OGHksfb2tpC1xn2ta+bY6wl5KhJsFicCXFubk5ERK5evSpnzpwREZGDBw/K448/biyGsMr78Oeff5ann37aUjSV/fLLL/LUU09VfM6JEydERKSvr89ESCJS2ocuvMH6yeVy8umnn1Zdz/r162V6ejqGiPw1NDTIzZs3Q69XPp7/+usvefjhhyPHMTU1JSLREm6QpBIyc8gA4Iqw86dicD6lvM10Op1IPNXE3dzcrJqbm43GMTIyokZGRqz2RVL72uR2lPvkk0+s91d5yY+vOCUV69TUlNa5i++//14rznfeecf42AvS29urent7E4vFWELOZDIqk8lo1V+pvbm5OTU3N1d1PFFKb29v7P0Sx0Az2Xa1g7C9vV21t7eXPG9oaKjkOe+9917isZW3mTc0NKSGhoa06xkfH090H1y/fl1dv37dd9xFkUScMzMzscaolFKNjY2JjcNiIyMjWs+v5g1bF1MWAOAK7dT9H4nw7qBzZKyUUk1NTYF19fT0qJ6enqriiVq8nDp1Sp06dcpaHPv37zfadtR+CtpXpqdggszOzqqmpibfMWkq1iTEFZvXFEUcRkdH1ejoaE2N37j2o5GE7MXro2uUukzsoIGBATUwMOC5HfX19aq+vt7aYOnq6rI2cMPsb9f2bV5jY2Pho3FTU5Nn7DpM9qVSwfOrftLpdKJxBfnjjz9iGStJlfwUVLH8tJGJ/gp9g/owxsfHPZdv2LBBLl++XHX9n3/+edV1BFEBl6u88sorIiIyOjqaeCxebLXr59133w29TlAfx6mjo6Pk/xs3bhT+npubkw0bNhT+v3Tpkladjz32WDzBlclkMr6PHT161HN5KpWSf/75Z8Hy/CWH8/PzVcVUabz9/fffIiKSTqcD62loaPBcvm3btmiBVSmfqzZt2rTgsTVr1hiLgzlkAHBF2I8conmIPjk56bl+a2tr5MP+rVu3RopFp6TTaZVOpyteSRHk6NGjhXrijC1f3njjjcD9cfz4cXX8+PFY9mGUUi5/iV4+tmw2q7LZbGBf5nK5xONzoZ5KZf/+/aH3oal9Xmz79u1Vj5Ok+zJsHHktLS1G2ilsv/YzQ3ZYtevr1BlHR8V9jWfe2rVrYx88u3bt8uyDXC6ncrlcqPhsDXCX4otaR/klc6b70uvyKxt9Gfe2Rbm+N0oZHh7WHIXx9aMupiwAwBVJvEt43bVNZz2/4iWuy2LC6uzsVOPj455nY+PcZt14o2xDkvGNjY1ptX348GGjcYmUXkUR10X+Opdqxj02y59X6VPe7du3E4svru2amZlRMzMzRtqu9jK9uPflgvqTCCiujRAR1dHREWvHlJfp6WnfbR0bG1MNDQ1a9fjNmccZa6gdq7FeUoO+paVFtbS0BF4OaKK/ykvxZW5x7IMkYw3qn8nJSd9xd/v2bSeTsdc5GpPtd3d3B7afxHkYXU4nZK9knMR1v/n7BTQ3N6tMJhO5nmr6TLeUf4HC7yurOvH19fWpvr4+oy+IfOnr6zPSX3GW2dlZNTs7azTW4qSrO95c7sNyJr4mH2e8UftXF3PIAOAK7dQd4p0hr7OzU3V2dsb6bhK2rqSLjVj9DAwM+F52l0qlnOrLWti3lWJ2KZZa6MdairW4DA4OxhK3rkQT8mIcaGHuvJVUDKtWrVKrVq0Ku+uc6k/X4gkq5dNnNmP58ccfffepi1+l99rfcczlmyh+r/dqt98PUxYA4IhE72WhSwXcy8DET+sU39Og2KOPPhqpviRjnpmZKbQR1Hd+bP1cUXd3t+fyu3fvGo4knIsXLxb+fuKJJ6zEcOHCBRERefbZZ32f49q9TUS8X99+r7elLtGEnN8RxS/+PXv2yEcffaRdh4nEETWplbOR5IrbHB8f97w5isj9myCdPXvWVFihpVIp2yEEOnfunIj8//uLpr344ou+j73++usGI9HntV9Nv06Kf+T0yJEj8uWXX2qvm18v79ixY7HGtoD25EaIuZPNmzeHrbbgzp071m9pGXd/UP4v3d3dnteCutyXLsRXyaFDh6z3kW7ce/bssdpnut8rEBH19ttvxzZGdTGHDACOSGTK4vz587Jly5bCRzxd33zzjXR1dSURUiyWL18ut27dsh3GopS/l65Liu+dbGvOXVWYTjtz5oyIiBw6dMhQNPr84v7444+ttD8xMSEiIjdv3gxcN5fLiYjIhx9+WLL8tddeiyk6f3Wq0h73WiHCwOzo6Cg5KXLy5MnCRmNpyZ/U++KLL0qW20p4lRS/NGzE99tvv8mKFSs8H/vpp5+M3jg9DK+UYrr/ymOo1H5xLtq0aZPs3LnT83nVbINumjWSkIFyxcPu9OnTvldf2GQ7IVd6abr4Oswfqb///vslyx966CG5c+eO0VhCpjVfExMTks1mq65HNx7mkAHAEU5ch4ylx8UjvGKzs7OFv23Funz5cvnzzz8L//f394uIyIEDB6zEE4WtvnN9fPlhygIAEsaUBQDUGBIyADiChAwAjiAhA4AjSMgA4AgSMgA4goQcYNmyZaLu/7JKofT09EhPT4/t0AAsMiRkAHAEXwypYPv27YU7anlZSn0BILpFcXOhMHdsMtH+xMSEPP/884X/H3nkEa3b+QFY2nTTrJP3spienvZc3tXVZeQ3w2y/EQBYmphDBgBHOHmEvG7dOs/lJn5VIq77qAJAWE7OIfuFZKNtpisAVKtm55AnJycXLHvhhRcSbzedTi9Y9tJLLyXeLgDkMYcMAI5wbsrC1g8kDg4OiojI7t27jbYLYPGrySmLw4cPL1j23XffGWm7OBEDgA1MWQCAI5w4Qs4fGe/bt2/BYy+//LLpcOTEiRPG2wQAJxKyVyIWEVm5cqXhSO779ttvrbQLYGmzflLPq/nnnntORESuXLkSa1th4+CkHoA48KvTAFBjrE1Z+L1jHDlyxOiRcTXS6bR88MEHJcvefPNNS9EAqHVWpiyefPJJ+fXXXxOrPwrdKYuBgQF56623tOrcsWOHiIh89dVX1QUHoKYxZQEANcb4lEVDQ4McPHjQ8zGbJ9GOHTsmIqVfEMlkMnLr1q3Id4DL/9oIJwcBaFEhiUhVZdeuXYnVHUcJY2xsTGt929tEoVDsFu38GioDxZBcXE9Y6XTad9uHh4crrjs1NeX89lEoFPNFF3PIAOAIYwlZ3T8aX7B87969pkLQMj8/7/vYgw8+KK2trYX/BwcHZX5+Xubn50UpJW1tbSXPr6urY/4YgDYjl71t3bpVvv76a8/H1q9f7/ujprY888wzIiJy9erV0OteunRJREQ2btwYa0wAapdummXKAgAcYeSyt88++8z3sVdffdW5I+Rr166JyP1PA+3t7bJixQoR+f8yNi/37t2TBx5w4l5NAGqUkSmLSk0wxwpgsXN6yqK/v58TXgBQhjlkAHCEkUlPjoQBIBhHyADgCBIyADiChAwAjiAhA4AjSMgA4AgSMgA4goQMAI4IfR1yyG9aAwA0cYQMAI4gIQOAI0jIAOAIEjIAOIKEDACOICEDgCNIyADgCBIyADiChAwAjiAhA4Aj/gU62WlqPmN06gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ansuini/.local/envs/pytorch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ansuini/.local/envs/pytorch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check labelling\n",
    "\n",
    "Useful in case of random shuffling of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(images[i,0,:,:])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(labels[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(loader):   \n",
    "    '''\n",
    "    Compute training statistics (loss and accuracy) on loader data\n",
    "    '''\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0       \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss += criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        l = loss.to('cpu').item()/total\n",
    "        acc = 100 * correct/total\n",
    "        return [l,acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize network, optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "criterion = F.nll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 24, 24]             260\n",
      "            Conv2d-2             [-1, 20, 8, 8]            5020\n",
      "            Linear-3                   [-1, 50]           16050\n",
      "            Linear-4                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: tensor(21840)\n",
      "Trainable params: tensor(21840)\n",
      "Non-trainable params: tensor(0)\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print( summary(model, imgs_shape) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:12<21:07, 12.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.221607 --- Train acc : 29.1833 %\n",
      "Test  loss : 0.221607 --- Test  acc : 29.64 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:25<20:56, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.1876 --- Train acc : 42.5233 %\n",
      "Test  loss : 0.187477 --- Test  acc : 42.24 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:38<20:42, 12.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.106879 --- Train acc : 74.95 %\n",
      "Test  loss : 0.105368 --- Test  acc : 75.82 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:51<20:26, 12.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0627602 --- Train acc : 82.6883 %\n",
      "Test  loss : 0.0605246 --- Test  acc : 83.6 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [01:04<20:18, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0486195 --- Train acc : 85.5867 %\n",
      "Test  loss : 0.0462041 --- Test  acc : 86.75 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [01:16<20:04, 12.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0409148 --- Train acc : 88.175 %\n",
      "Test  loss : 0.038701 --- Test  acc : 88.91 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [01:29<19:54, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0373726 --- Train acc : 88.5667 %\n",
      "Test  loss : 0.0350019 --- Test  acc : 89.61 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [01:42<19:39, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0351395 --- Train acc : 89.135 %\n",
      "Test  loss : 0.032801 --- Test  acc : 90.14 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [01:55<19:29, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0305798 --- Train acc : 91.0083 %\n",
      "Test  loss : 0.0284441 --- Test  acc : 91.69 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [02:08<19:16, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0301541 --- Train acc : 90.78 %\n",
      "Test  loss : 0.0283097 --- Test  acc : 91.54 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [02:21<19:05, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0264189 --- Train acc : 92.1967 %\n",
      "Test  loss : 0.0245541 --- Test  acc : 92.72 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [02:34<18:51, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0250346 --- Train acc : 92.5467 %\n",
      "Test  loss : 0.0232422 --- Test  acc : 93.15 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [02:47<18:39, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0234596 --- Train acc : 93.1367 %\n",
      "Test  loss : 0.0218548 --- Test  acc : 93.66 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [03:00<18:26, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.02227 --- Train acc : 93.5217 %\n",
      "Test  loss : 0.020619 --- Test  acc : 93.94 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [03:13<18:16, 12.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0212064 --- Train acc : 93.8033 %\n",
      "Test  loss : 0.0195711 --- Test  acc : 94.23 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [03:26<18:03, 12.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0209736 --- Train acc : 93.7483 %\n",
      "Test  loss : 0.019304 --- Test  acc : 94.2 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [03:39<17:52, 12.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0194561 --- Train acc : 94.3783 %\n",
      "Test  loss : 0.0179911 --- Test  acc : 94.89 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [03:53<17:41, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0187408 --- Train acc : 94.535 %\n",
      "Test  loss : 0.0173087 --- Test  acc : 94.84 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [04:06<17:31, 12.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.017741 --- Train acc : 94.8583 %\n",
      "Test  loss : 0.0162352 --- Test  acc : 95.16 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [04:19<17:18, 12.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0172411 --- Train acc : 95.0467 %\n",
      "Test  loss : 0.0157871 --- Test  acc : 95.4 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [04:32<17:05, 12.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.016468 --- Train acc : 95.2283 %\n",
      "Test  loss : 0.0150191 --- Test  acc : 95.55 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [04:46<16:54, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0162387 --- Train acc : 95.2483 %\n",
      "Test  loss : 0.0146706 --- Test  acc : 95.75 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [04:59<16:42, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0155217 --- Train acc : 95.4633 %\n",
      "Test  loss : 0.0140644 --- Test  acc : 95.86 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [05:12<16:28, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0150396 --- Train acc : 95.675 %\n",
      "Test  loss : 0.0135002 --- Test  acc : 95.94 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [05:26<16:18, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0145273 --- Train acc : 95.765 %\n",
      "Test  loss : 0.0131186 --- Test  acc : 96.18 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [05:39<16:06, 13.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0141729 --- Train acc : 95.9033 %\n",
      "Test  loss : 0.0125423 --- Test  acc : 96.32 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [05:52<15:54, 13.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0137788 --- Train acc : 95.9783 %\n",
      "Test  loss : 0.0122607 --- Test  acc : 96.39 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [06:06<15:42, 13.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0134182 --- Train acc : 96.1567 %\n",
      "Test  loss : 0.0119084 --- Test  acc : 96.5 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [06:19<15:29, 13.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0131674 --- Train acc : 96.1433 %\n",
      "Test  loss : 0.0118311 --- Test  acc : 96.68 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [06:33<15:17, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0127747 --- Train acc : 96.265 %\n",
      "Test  loss : 0.0113918 --- Test  acc : 96.49 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [06:46<15:05, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0124686 --- Train acc : 96.295 %\n",
      "Test  loss : 0.0110087 --- Test  acc : 96.75 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [07:00<14:53, 13.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0120255 --- Train acc : 96.5317 %\n",
      "Test  loss : 0.0106662 --- Test  acc : 96.93 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [07:14<14:41, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0119135 --- Train acc : 96.545 %\n",
      "Test  loss : 0.0104478 --- Test  acc : 96.96 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [07:27<14:29, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0116731 --- Train acc : 96.645 %\n",
      "Test  loss : 0.0103871 --- Test  acc : 96.97 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [07:41<14:17, 13.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0114453 --- Train acc : 96.6383 %\n",
      "Test  loss : 0.010188 --- Test  acc : 97.09 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [07:54<14:03, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0110573 --- Train acc : 96.8117 %\n",
      "Test  loss : 0.00991438 --- Test  acc : 97.16 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [08:07<13:50, 13.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0109902 --- Train acc : 96.79 %\n",
      "Test  loss : 0.00972714 --- Test  acc : 97.14 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [08:22<13:39, 13.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 0.0108482 --- Train acc : 96.7983 %\n",
      "Test  loss : 0.00941996 --- Test  acc : 97.16 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-233:\n",
      "Process Process-234:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ansuini/.local/envs/pytorch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ansuini/.local/envs/pytorch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/ansuini/.local/envs/pytorch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ansuini/.local/envs/pytorch/lib/python3.5/site-packages/torchvision/datasets/mnist.py\", line 74, in __getitem__\n",
      "    img = Image.fromarray(img.numpy(), mode='L')\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Exception in thread Thread-121:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ansuini/.local/envs/pytorch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 71, in _worker_manager_loop\n",
      "    r = in_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 345, in get\n",
      "    return ForkingPickler.loads(res)\n",
      "  File \"/home/ansuini/.local/envs/pytorch/lib/python3.5/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 10157) exited unexpectedly with exit code 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2909\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2910\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2911\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-01ad743235b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m# get statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mtrain_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mtest_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-cf7df40e6f7b>\u001b[0m in \u001b[0;36mget_stats\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1827\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1828\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1829\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;31m# (5 blanks lines) where none should be returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_fixed_getinnerframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36m_fixed_getinnerframes\u001b[0;34m(etb, context, tb_offset)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_frame_records_filenames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetinnerframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m     \u001b[0;31m# If the error is at the console, don't build any context, since it would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mgetinnerframes\u001b[0;34m(tb, context)\u001b[0m\n\u001b[1;32m   1452\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m         \u001b[0mframeinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb_frame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgetframeinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1454\u001b[0m         \u001b[0mframelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrameInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mframeinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;31m# only return a non-existent filename if the module has a PEP 302 loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__loader__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/inspect.py\u001b[0m in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    717\u001b[0m             modulesbyfile[f] = modulesbyfile[\n\u001b[0;32m--> 718\u001b[0;31m                 os.path.realpath(f)] = module.__name__\n\u001b[0m\u001b[1;32m    719\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodulesbyfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/posixpath.py\u001b[0m in \u001b[0;36mrealpath\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    371\u001b[0m symbolic links encountered in the path.\"\"\"\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_joinrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/posixpath.py\u001b[0m in \u001b[0;36m_joinrealpath\u001b[0;34m(path, rest, seen)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mnewpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mislink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mpath\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBytesWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 9444) exited unexpectedly with exit code 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1829\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1831\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1371\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1279\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m             )\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1128\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0mtb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb_offset\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtb_offset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m         \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;31m# So far, I haven't been able to find an isolated example to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0;31m# reproduce the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m             \u001b[0minspect_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mostream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nUnfortunately, your original traceback can not be constructed.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36minspect_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m     These are unfortunately quite common.\"\"\"\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     error('Internal Python error in the inspect module.\\n'\n\u001b[0m\u001b[1;32m    148\u001b[0m           'Below is the traceback from this internal error.\\n')\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/logging/__init__.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1802\u001b[0m     \"\"\"\n\u001b[1;32m   1803\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1804\u001b[0;31m         \u001b[0mbasicConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1805\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/logging/__init__.py\u001b[0m in \u001b[0;36mbasicConfig\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m                 \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/logging/__init__.py\u001b[0m in \u001b[0;36maddHandler\u001b[0;34m(self, hdlr)\u001b[0m\n\u001b[1;32m   1429\u001b[0m         \u001b[0mAdd\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \"\"\"\n\u001b[0;32m-> 1431\u001b[0;31m         \u001b[0m_acquireLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhdlr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/logging/__init__.py\u001b[0m in \u001b[0;36m_acquireLock\u001b[0;34m()\u001b[0m\n\u001b[1;32m    216\u001b[0m     \"\"\"\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_releaseLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/envs/pytorch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 10157) exited unexpectedly with exit code 1."
     ]
    }
   ],
   "source": [
    "train_stats = []\n",
    "test_stats  = []\n",
    "fractions   = []\n",
    "grad_stats  = []\n",
    "grad2_stats = []\n",
    "snr_stats   = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    # init accumulators grad and grad2\n",
    "    grad  = init_grad(model)\n",
    "    grad2 = init_grad(model)  \n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "                       \n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)  \n",
    "       \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)        \n",
    "        # compute the grad\n",
    "        loss.backward()\n",
    "                \n",
    "        # accumulate grad and grad2\n",
    "        grad  = acc_grad(grad,model)\n",
    "        grad2 = acc_grad2(grad2,model)\n",
    "        \n",
    "        if (i + 1) % n == 0 : \n",
    "            \n",
    "            # compute the snr \n",
    "            snr = compute_snr(grad, grad2, n, mb_size)\n",
    "            \n",
    "            # temper the grad with the information on grad2\n",
    "            fr = []\n",
    "            with torch.no_grad():\n",
    "                for p, g, s in zip(model.parameters(), grad, snr): \n",
    "                    \n",
    "                    \n",
    "                    # this is the only line where the true gradient is touched\n",
    "                    if MODIFIED_SGD:\n",
    "                        p.grad = torch.where(s > 1, g/n, s * g/n)          \n",
    "                    else:\n",
    "                        p.grad = g/n\n",
    "                        \n",
    "                    fr.append(  ( s < 1).sum().item() / \n",
    "                             torch.prod(torch.tensor( s.size() ) ).item()  )       \n",
    "            fractions.append(fr)\n",
    "    \n",
    "            # store statistics about grad, grad2 and snr    \n",
    "            grad_stats.append(  [ [x.mean().item(), x.std().item()]  for x in grad] )\n",
    "            grad2_stats.append( [ [x.mean().item(), x.std().item()]  for x in grad2] )\n",
    "            snr_stats.append(   [ [x.mean().item(), x.std().item()]  for x in snr] )\n",
    "        \n",
    "            # this is called after the large batch of n mini-batches\n",
    "            optimizer.step()\n",
    "            \n",
    "            # set to zero accumulators for grad and grad2\n",
    "            grad  = init_grad(model)\n",
    "            grad2 = init_grad(model)\n",
    "            \n",
    "                          \n",
    "    # save model\n",
    "    if SAVE:\n",
    "        #model.save_state_dict(model, os.path.join( RES, 'model_' + str(epoch) + '.pt') )\n",
    "        torch.save(model, os.path.join( RES, 'model_' + str(epoch) + '.pt') )\n",
    "        \n",
    "    # get statistics\n",
    "    train_stats.append(get_stats(train_loader))\n",
    "    test_stats.append(get_stats(test_loader))\n",
    "        \n",
    "    # print statistics\n",
    "    print('Train loss : %g --- Train acc : %g %%' % ( train_stats[-1][0], train_stats[-1][1] )) \n",
    "    print('Test  loss : %g --- Test  acc : %g %%' % ( test_stats[-1][0],  test_stats[-1][1] ))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save loss and accuracies in a dictionary\n",
    "train_stats = np.asarray(train_stats)\n",
    "test_stats  = np.asarray(test_stats)\n",
    "fractions   = np.asarray(fractions)\n",
    "grad_stats  = np.asarray(grad_stats)\n",
    "grad2_stats = np.asarray(grad2_stats)\n",
    "snr_stats   = np.asarray(snr_stats)\n",
    "\n",
    "tags = ['train_stats', 'test_stats', 'fractions' ]\n",
    "vals = [train_stats, test_stats, fractions]\n",
    "training_data = dict(zip(tags, vals))\n",
    "if SAVE:\n",
    "    file = open( os.path.join( RES, 'training_data.pt') , 'wb' ) \n",
    "    pickle.dump(training_data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 30\n",
    "layer_names = [m[0] for idx,m in enumerate(model.named_modules()) ][1:]\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "plt.subplot(3,3,1)\n",
    "plt.plot(train_stats[:,0],'-o',label='training loss')\n",
    "plt.plot(test_stats[:,0],'-o',label='test loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('loss')\n",
    "\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "plt.plot(train_stats[:,1],'-o',label='training accuracy')\n",
    "plt.plot(test_stats[:,1],'-o',label='test accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.title('accuracy')\n",
    "\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "for i in range(len(layer_names)):\n",
    "    plt.plot(np.arange(n_lb*epochs), pd.rolling_mean(fractions[:,i*2], win*2 ),label=layer_names[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.title('fractions')\n",
    "\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "for i in range(len(layer_names)):\n",
    "    plt.plot(pd.rolling_mean( grad_stats[:,i*2,0], win ),label=layer_names[i])\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.title('grad mean')\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "for i in range(len(layer_names)):\n",
    "    plt.plot(pd.rolling_mean( grad_stats[:,i*2,1], win ),label=layer_names[i])\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.title('grad std')\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "for i in range(len(layer_names)):\n",
    "    plt.plot(pd.rolling_mean( grad2_stats[:,i*2,0], win),label=layer_names[i])\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.title('grad2 mean')\n",
    "\n",
    "plt.subplot(3,3,7)\n",
    "for i in range(len(layer_names)):\n",
    "    plt.plot(pd.rolling_mean( grad2_stats[:,i*2,1], win),label=layer_names[i])\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.title('grad2 std')\n",
    "\n",
    "\n",
    "plt.subplot(3,3,8)\n",
    "for i in range(len(layer_names)):\n",
    "    plt.plot(pd.rolling_mean( snr_stats[:,i*2,0], win),label=layer_names[i])\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.title('snr mean')\n",
    "\n",
    "plt.subplot(3,3,9)\n",
    "for i in range(len(layer_names)):\n",
    "    plt.plot(pd.rolling_mean( snr_stats[:,i*2,1], win),label=layer_names[i])\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.title('snr std')\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(FIG, 'mnist.png'))\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 0.4.0",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
